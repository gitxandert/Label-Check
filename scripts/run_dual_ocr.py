"""
This script serves as the second step in a data processing pipeline for whole-slide images (WSIs).
It takes a CSV file generated by a previous script (which maps original slides to their
extracted label and macro images) and enriches it by performing Optical Character Recognition (OCR)
on these images.

The script is designed to be robust and efficient:
- It uses EasyOCR for text extraction, with support for both GPU and CPU processing.
- Image preprocessing techniques (grayscale, binarization) are applied to enhance OCR accuracy.
- It handles file paths intelligently, resolving them relative to the input CSV's location.
- Parallel processing is implemented using a thread pool to significantly speed up the OCR
  task on multiple files.
- A progress bar provides real-time feedback on the processing status.

The output is a new, enriched CSV file containing all the original data plus new columns for the
extracted text from both label and macro images, and a flag indicating if the row was
successfully processed by OCR.
"""

# ==============================================================================
# 1. IMPORTS
# ==============================================================================
import argparse
import csv
import logging
from concurrent.futures import ThreadPoolExecutor, as_completed
from pathlib import Path

# Third-party libraries for image processing and OCR
import cv2  # OpenCV for image manipulation
import easyocr  # The core OCR engine
import numpy as np  # For numerical operations on images
import PIL  # Python Imaging Library (Pillow) for opening images
from tqdm import tqdm  # For displaying a progress bar


# ==============================================================================
# 2. CONFIGURATION
# ==============================================================================

# Set up a logger for informative console output.
# The format includes timestamp, log level, and the message.
logging.basicConfig(
    level=logging.INFO, format="%(asctime)s - %(levelname)s - %(message)s"
)
logger = logging.getLogger(__name__)


# ==============================================================================
# 3. HELPER FUNCTIONS
# ==============================================================================

def clean_and_resolve_path(path_str: str) -> Path | None:
    """
    Cleans a potentially messy path string and resolves it to an absolute Path object.

    This function is designed to handle path inconsistencies, such as different
    slash types or relative path prefixes, making file access more reliable.

    Args:
        path_str (str): The input path string, which might contain backslashes or './'.

    Returns:
        Path | None: A resolved, absolute Path object if the input string is not empty,
                     otherwise None.
    """
    if not path_str:
        return None

    # 1. Standardize path separators to forward slashes, which work across platforms.
    cleaned_str = path_str.replace("\\", "/")

    # 2. Remove any leading './' prefix, as this can interfere with path resolution
    #    when the script's working directory differs from the file's location.
    if cleaned_str.startswith("./"):
        cleaned_str = cleaned_str[2:]

    # 3. Create a Path object and use .resolve() to get the canonical, absolute path.
    #    This is crucial for ensuring the script can find the images regardless of
    #    where it is executed from.
    return Path(cleaned_str).resolve()


def preprocess_image_for_ocr(image_np: np.ndarray) -> np.ndarray:
    """
    Applies a series of image processing techniques to an image to improve OCR accuracy.

    The steps are:
    1. Convert the image to grayscale.
    2. Apply Otsu's binarization to create a high-contrast black and white image.
    3. Convert the binarized image back to a 3-channel format required by EasyOCR.

    Args:
        image_np (np.ndarray): The input image as a NumPy array in RGB format.

    Returns:
        np.ndarray: The preprocessed 3-channel image ready for OCR.
    """
    # OpenCV works with BGR color order by default, while PIL (used for opening) uses RGB.
    # We must convert from the RGB NumPy array to grayscale.
    gray_image = cv2.cvtColor(image_np, cv2.COLOR_RGB2GRAY)

    # Apply binarization. Otsu's method is effective because it automatically calculates
    # the optimal threshold value to separate text from the background, adapting to
    # different lighting conditions in the images.
    _, binary_image = cv2.threshold(
        gray_image, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU
    )

    # EasyOCR expects a 3-channel (RGB-like) image, even if it's grayscale.
    # We convert the single-channel binary image back to a 3-channel representation.
    three_channel_image = cv2.cvtColor(binary_image, cv2.COLOR_GRAY2RGB)
    return three_channel_image


def perform_ocr_on_row(row: dict, csv_dir: Path, reader: easyocr.Reader) -> dict:
    """
    A worker function that performs OCR on the label and macro images for a single CSV row.

    This function is designed to be executed in a separate thread. It handles path resolution,
    image loading, preprocessing, OCR execution, and error handling for one data entry.

    Args:
        row (dict): A dictionary representing one row from the input CSV.
        csv_dir (Path): The parent directory of the input CSV file. This is not used
                      in the current implementation with `clean_and_resolve_path`
                      but is kept for potential future use with purely relative paths.
        reader (easyocr.Reader): The initialized EasyOCR reader instance, shared across threads.

    Returns:
        dict: The original row dictionary, updated with 'label_text', 'macro_text',
              and 'ocr_qc_needed' fields.
    """
    updated_row = row.copy()
    label_text = ""
    macro_text = ""
    # This flag indicates whether OCR was successfully performed. It's used later
    # to know if a row's data might need manual verification.
    ocr_qc_needed = False

    # --- Step 1: Resolve and Validate Image Paths ---
    label_path_str = row.get("label_path")
    macro_path_str = row.get("macro_path")

    paths_to_process = {}
    if label_path_str:
        label_path = clean_and_resolve_path(label_path_str)
        if label_path and label_path.exists():
            paths_to_process["label"] = label_path
        else:
            logger.warning(f"Label image not found at resolved path '{label_path}' for row: {row}")

    if macro_path_str:
        macro_path = clean_and_resolve_path(macro_path_str)
        if macro_path and macro_path.exists():
            paths_to_process["macro"] = macro_path
        else:
            logger.warning(f"Macro image not found at resolved path '{macro_path}' for row: {row}")

    # Proceed only if at least one image file was found.
    if paths_to_process:
        try:
            # --- Step 2: Process Label Image (if it exists) ---
            if "label" in paths_to_process:
                image_label_pil = PIL.Image.open(paths_to_process["label"])
                image_label_np = np.array(image_label_pil)
                processed_label = preprocess_image_for_ocr(image_label_np)
                ocr_results = reader.readtext(processed_label)
                # Concatenate all detected text fragments into a single string.
                label_text = " ".join([text for _, text, _ in ocr_results])

            # --- Step 3: Process Macro Image (if it exists) ---
            if "macro" in paths_to_process:
                image_macro_pil = PIL.Image.open(paths_to_process["macro"])
                
                # --- Apply specific transformations for macro images ---
                # The text on macro images is often sideways. Rotating it helps the OCR engine.
                img_macro_pil = image_macro_pil.rotate(-90, expand=True)
                width, height = img_macro_pil.size
                # Crop the image to focus on the area most likely to contain text,
                # removing irrelevant parts of the slide.
                crop_box = (
                    (0, 0, width / 2, height)
                    if width > height
                    else (0, 0, width, height / 2)
                )
                img_macro_pil = img_macro_pil.crop(crop_box)

                image_macro_np = np.array(img_macro_pil)
                processed_macro = preprocess_image_for_ocr(image_macro_np)
                # Inform EasyOCR to check for text at multiple rotations.
                ocr_results = reader.readtext(
                    processed_macro, rotation_info=[0, 90, 180, 270]
                )
                macro_text = " ".join([text for _, text, _ in ocr_results])

            # If the process completes without errors for at least one image, mark it.
            ocr_qc_needed = True

        except Exception as e:
            # If any error occurs (e.g., corrupted image), log it but don't crash.
            # The row will be written to the output CSV without OCR data.
            logger.error(f"Failed OCR on row for slide '{row.get('original_slide_path')}': {e}")
            ocr_qc_needed = False

    # --- Step 4: Update the row with OCR results ---
    updated_row["label_text"] = label_text
    updated_row["macro_text"] = macro_text
    updated_row["ocr_qc_needed"] = ocr_qc_needed

    return updated_row


# ==============================================================================
# 4. MAIN ORCHESTRATION FUNCTION
# ==============================================================================

def add_ocr_to_mapping(
    mapping_csv: Path, output_csv: Path, use_cpu: bool, num_workers: int
):
    """
    Reads a mapping CSV, orchestrates the OCR process for all rows using a thread pool,
    and writes the enriched data to a new CSV file.

    Args:
        mapping_csv (Path): Path to the input CSV file.
        output_csv (Path): Path where the enriched output CSV will be saved.
        use_cpu (bool): If True, forces EasyOCR to use the CPU. Otherwise, it will try to use a GPU.
        num_workers (int): The number of concurrent threads to use for OCR processing.
    """
    if not mapping_csv.exists():
        logger.error(f"Input mapping CSV not found: {mapping_csv}")
        return

    logger.info("Initializing EasyOCR reader... (This may take a moment)")
    # Initialize the OCR reader once and share it among all threads.
    # GPU is generally much faster if available.
    reader = easyocr.Reader(["en"], gpu=not use_cpu)

    # Read the entire CSV into a list of dictionaries.
    with open(mapping_csv, "r", encoding="utf-8") as f:
        reader_csv = csv.DictReader(f)
        rows = list(reader_csv)

    if not rows:
        logger.warning("Input CSV is empty. Nothing to process.")
        return

    updated_rows = []
    # This is not strictly necessary with the current path resolution but is good practice.
    csv_dir = mapping_csv.parent

    # Use a ThreadPoolExecutor to manage a pool of worker threads.
    with ThreadPoolExecutor(max_workers=num_workers) as executor:
        # Submit an OCR task for each row in the CSV. This returns a 'future' object
        # for each task, which represents a pending result.
        future_to_row = {
            executor.submit(perform_ocr_on_row, row, csv_dir, reader): row
            for row in rows
        }

        # Use tqdm to create a progress bar. as_completed yields futures as they finish,
        # which allows for real-time progress updates.
        progress_bar = tqdm(
            as_completed(future_to_row), total=len(rows), desc="Running OCR"
        )
        for future in progress_bar:
            # Retrieve the result (the updated row dictionary) from the completed future.
            updated_rows.append(future.result())

    if not updated_rows:
        logger.error("Processing failed catastrophically. No rows were updated.")
        return

    # --- Write the updated data to the new CSV file ---
    # Dynamically determine the headers from the first processed row. This ensures
    # that the new OCR-related columns are included.
    headers = list(updated_rows[0].keys())

    logger.info(f"Writing {len(updated_rows)} enriched rows to {output_csv}...")
    try:
        with open(output_csv, "w", newline="", encoding="utf-8") as f:
            writer = csv.DictWriter(f, fieldnames=headers)
            writer.writeheader()
            writer.writerows(updated_rows)
        logger.info("Successfully created enriched CSV.")
    except Exception as e:
        logger.error(f"Failed to write the output CSV file: {e}")


# ==============================================================================
# 5. SCRIPT EXECUTION
# ==============================================================================

if __name__ == "__main__":
    # Set up the command-line argument parser to make the script configurable.
    parser = argparse.ArgumentParser(
        description="Enrich a slide mapping CSV with OCR text from label and macro images."
    )
    parser.add_argument(
        "--mapping-csv",
        type=Path,
        required=True,
        help="Path to the input CSV file generated by the first script (e.g., slide_mapping.csv).",
    )
    parser.add_argument(
        "--output-csv",
        type=Path,
        required=True,
        help="Path to save the new CSV file with added OCR columns.",
    )
    parser.add_argument(
        "--workers",
        type=int,
        default=4,
        help="Number of worker threads for parallel processing.",
    )
    parser.add_argument(
        "--use-cpu",
        action="store_true",
        help="Force EasyOCR to use CPU instead of GPU. Use this if you don't have a compatible GPU.",
    )

    args = parser.parse_args()

    # Ensure the directory for the output file exists before trying to write to it.
    args.output_csv.parent.mkdir(parents=True, exist_ok=True)

    # Call the main function with the parsed command-line arguments.
    add_ocr_to_mapping(args.mapping_csv, args.output_csv, args.use_cpu, args.workers)
